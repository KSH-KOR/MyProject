import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
%matplotlib inline

from sklearn.datasets import load_breast_cancer

cancer=load_breast_cancer()
cancer.keys()
print(cancer.DESCR)

df=pd.DataFrame(cancer['data'], columns=cancer['feature_names'])
df.head(5)

/*
what we try to do is reducing this 30 dimension into two dimension which will be creating a new vector space by using pca

first thing to do is standard scaling

the main reason is the difference between these values on different attributes should be very minimal if you are trying to create a new vector space so you can use standard scaling or min max scaler which convert all the values between 0 and 1

1.first thing to do is standard scaling
2.항목 추가
*/

from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

scaler=StandardScaler()
scaler.fit(df)

scaled_data=scaler.transform(df)
scaled_data

pca=PCA(n_components=2)
//n_components is the number of components you want to reduce a dimension to
pca.fit(scaled_data)
x_pca=pca.transform(scaled_data)

scaled_data.shape
x_pca.shape

scaled_data
x_pca

plt.figure(figsize=(8,6))
plt.scatter(x_pca[:,0], x_pca[:,1], c=cancer['target'])
plt.xlabel('First principal component')
plt.ylabel('Second principal component')
